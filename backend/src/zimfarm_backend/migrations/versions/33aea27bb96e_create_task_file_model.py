"""create task file model


Revision ID: 33aea27bb96e
Revises: c1716b0a1595
Create Date: 2025-11-06 16:07:21.385887

"""

import json
import logging
from typing import Any, cast

import sqlalchemy as sa
from alembic import op
from psycopg.types.json import Jsonb
from sqlalchemy.dialects import postgresql
from sqlalchemy.orm import Session

from zimfarm_backend.db import zimfarm_dumps, zimfarm_loads

# revision identifiers, used by Alembic.
revision = "33aea27bb96e"
down_revision = "c1716b0a1595"
branch_labels = None
depends_on = None

logger = logging.getLogger("alembic.runtime.migration")


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "file",
        sa.Column(
            "id",
            sa.Uuid(),
            server_default=sa.text("uuid_generate_v4()"),
            nullable=False,
        ),
        sa.Column("name", sa.String(), nullable=False),
        sa.Column("status", sa.String(), nullable=False),
        sa.Column("size", sa.BigInteger(), nullable=True),
        sa.Column("cms_on", sa.DateTime(), nullable=True),
        sa.Column("cms_notified", sa.Boolean(), nullable=True),
        sa.Column("created_timestamp", sa.DateTime(), nullable=True),
        sa.Column("uploaded_timestamp", sa.DateTime(), nullable=True),
        sa.Column("failed_timestamp", sa.DateTime(), nullable=True),
        sa.Column("check_timestamp", sa.DateTime(), nullable=True),
        sa.Column("check_result", sa.Integer(), nullable=True),
        sa.Column("check_log", sa.String(), nullable=True),
        sa.Column(
            "check_details", postgresql.JSONB(astext_type=sa.Text()), nullable=True
        ),
        sa.Column(
            "info",
            postgresql.JSONB(astext_type=sa.Text()),
            server_default="{}",
            nullable=False,
        ),
        sa.Column("task_id", sa.Uuid(), nullable=False),
        sa.ForeignKeyConstraint(
            ["task_id"], ["task.id"], name=op.f("fk_file_task_id_task")
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("pk_file")),
        sa.UniqueConstraint("task_id", "name", name=op.f("uq_file_task_id")),
    )
    op.create_index(
        op.f("ix_file_cms_notified"), "file", ["cms_notified"], unique=False
    )
    # ### end Alembic commands ###

    bind = op.get_bind()
    session = Session(bind=bind)
    # Migrate data from task.files to file table

    result = session.execute(sa.text("SELECT id FROM task"))
    task_ids = [row[0] for row in result]

    for task_id in task_ids:
        # Fetch task from files column
        task_result = session.execute(
            sa.text("SELECT files FROM task WHERE id = :task_id"),
            {"task_id": task_id},
        )
        task_row = task_result.fetchone()

        if not task_row or not task_row[0]:
            continue

        task_files: dict[str, Any] | None = task_row[0]

        if not isinstance(task_files, dict):
            continue

        for filename, file_data in task_files.items():
            if not isinstance(file_data, dict):
                continue
            file_data = cast(dict[str, Any], file_data)

            # Extract CMS data if present
            cms_data = file_data.get("cms")
            cms_on = None

            if cms_data and isinstance(cms_data, dict):
                cms_data = cast(dict[str, Any], cms_data)
                cms_on = (
                    zimfarm_loads(json.dumps(cms_data.get("on")))
                    if cms_data.get("on")
                    else None
                )

            # Insert file entry
            session.execute(
                sa.text(
                    """
                    INSERT INTO file (
                        name, status, size,
                        cms_on, cms_notified,
                        created_timestamp, uploaded_timestamp,
                        failed_timestamp, check_timestamp,
                        check_result, check_log, check_details, info,
                        task_id
                    ) VALUES (
                        :name, :status, :size,
                        :cms_on, :cms_notified,
                        :created_timestamp, :uploaded_timestamp,
                        :failed_timestamp, :check_timestamp,
                        :check_result, :check_log, :check_details, :info,
                        :task_id
                    )
                """
                ),
                {
                    "name": filename,
                    "status": file_data.get("status"),
                    "size": file_data.get("size"),
                    "cms_on": cms_on,
                    "cms_notified": None,  # Not in original schema
                    "created_timestamp": (
                        zimfarm_loads(json.dumps(file_data.get("created_timestamp")))
                        if file_data.get("created_timestamp")
                        else None
                    ),
                    "uploaded_timestamp": (
                        zimfarm_loads(json.dumps(file_data.get("uploaded_timestamp")))
                        if file_data.get("uploaded_timestamp")
                        else None
                    ),
                    "failed_timestamp": (
                        zimfarm_loads(json.dumps(file_data.get("failed_timestamp")))
                        if file_data.get("failed_timestamp")
                        else None
                    ),
                    "check_timestamp": (
                        zimfarm_loads(json.dumps(file_data.get("check_timestamp")))
                        if file_data.get("check_timestamp")
                        else None
                    ),
                    "check_result": file_data.get("check_result"),
                    "check_log": file_data.get("check_log"),
                    "check_details": Jsonb(
                        zimfarm_loads(json.dumps(file_data.get("check_details", {})))
                    ),
                    "info": Jsonb(zimfarm_loads(json.dumps(file_data.get("info", {})))),
                    "task_id": task_id,
                },
            )
            logger.info(f"Created {filename} record for task {task_id}")

    # remove the old files column
    op.drop_column("task", "files")


def downgrade() -> None:
    # Migrate data from file table back to task.files
    op.add_column(
        "task",
        sa.Column(
            "files",
            postgresql.JSONB(astext_type=sa.Text()),
            autoincrement=False,
            nullable=False,
            server_default="{}",
        ),
    )
    bind = op.get_bind()
    session = Session(bind=bind)

    # Get all tasks with their associated files
    result = session.execute(sa.text("SELECT DISTINCT task_id FROM file"))
    task_ids = [row[0] for row in result]

    for task_id in task_ids:
        # Fetch all files for this task
        files_result = session.execute(
            sa.text(
                """
                SELECT
                    name, status, size,
                    cms_on, created_timestamp, uploaded_timestamp,
                    failed_timestamp, check_timestamp,
                    check_result, check_log, check_details, info
                FROM file
                WHERE task_id = :task_id
            """
            ),
            {"task_id": task_id},
        )

        files_dict = {}
        for row in files_result:
            file_data: dict[str, Any] = {
                "name": row[0],
                "status": row[1],
                "size": row[2],
                "created_timestamp": (
                    json.loads(zimfarm_dumps(row[4])) if row[4] else None
                ),
                "uploaded_timestamp": (
                    json.loads(zimfarm_dumps(row[5])) if row[5] else None
                ),
                "failed_timestamp": (
                    json.loads(zimfarm_dumps(row[6])) if row[6] else None
                ),
                "check_timestamp": (
                    json.loads(zimfarm_dumps(row[7])) if row[7] else None
                ),
                "check_result": row[8],
                "check_log": row[9],
                "check_details": (
                    json.loads(zimfarm_dumps(row[10])) if row[10] else {}
                ),
                "info": json.loads(zimfarm_dumps(row[11] if row[11] else {})),
            }

            # Add CMS data if any field is present
            if row[3] is not None:
                cms_data: dict[str, Any] = {"on": json.loads(zimfarm_dumps(row[3]))}

                if cms_data:
                    file_data["cms"] = cms_data

            files_dict[row[0]] = file_data

        # Update task.files column
        if files_dict:
            session.execute(
                sa.text("UPDATE task SET files = :files WHERE id = :task_id"),
                {"files": Jsonb(files_dict), "task_id": task_id},
            )
            logger.info(f"Updated task {task_id} with files")

    op.drop_index(op.f("ix_file_cms_notified"), table_name="file")
    op.drop_table("file")
